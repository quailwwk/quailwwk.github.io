---
title: "Single-sequence protein structure prediction using supervised transformer protein language models"
collection: publications
permalink: /publication/trRosettaX-Single
excerpt: 'In this article, we introduce trRosettaX-Single, a deep learning-based **single-sequence protein structure prediction method** with a supervised transformer protein language model. Benchmark tests show that our method **outperforms AlphaFold2 and RoseTTAFold on orphan proteins**. As a demonstration, trRosettaX-Single is applied to protein design/hallucination and missense mutation analysis.'
date: 2022-12-19
venue: 'Nature Computational Science'
paperurl: 'https://www.nature.com/articles/s43588-022-00373-3'
citation: 'Wenkai Wang, Zhenling Peng, Jianyi Yang*, Single-sequence protein structure prediction using supervised transformer protein language models. <I>Nature Computational Science</i>, 2: 804-814 (2022).'
---
In this article, we introduce trRosettaX-Single, a deep learning-based **single-sequence protein structure prediction method** with a supervised transformer protein language model. Benchmark tests show that our method **outperforms AlphaFold2 and RoseTTAFold on orphan proteins**. On human-designed proteins, trRosettaX-Single is competitive with AlphaFold2 and outperforms RoseTTAFold. trRosettaX-Single also generates much more accurate contact prediction than SPOT-Contact-LM on all independent test sets. Finally, as a demonstration, trRosettaX-Single is applied to protein design/hallucination and missense mutation analysis.

[[Download paper here](https://yanglab.qd.sdu.edu.cn/papers/Wang_NatureCS_2022.pdf)] [[Supporting Information](https://yanglab.qd.sdu.edu.cn/papers/Wang_NatureCS_2022_SI.pdf)] [[Web server](https://yanglab.qd.sdu.edu.cn/trRosetta/)]

This work was featured by Nature CS and selected as [research highlights by Nature Methods](https://www.nature.com/articles/s41592-023-01795-1).

**Wenkai Wang**, Zhenling Peng, Jianyi Yang*, Single-sequence protein structure prediction using supervised transformer protein language models. _Nature Computational Science_, 2: 804-814 (2022).
